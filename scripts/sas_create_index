#!/usr/bin/env python
import os
import datetime
import argparse
import base64
import common
import sys

def sanitize_path(path):
    sanitized_path = path.strip(os.sep)
    sanitized_path = sanitized_path.replace(os.sep, "_")
    sanitized_path = sanitized_path.replace(".", "")
    return(sanitized_path)


if __name__ == "__main__":
    parser = argparse.ArgumentParser("Formatter summary creator", formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument("source_dir", type=str, help='path to the source directory')
    parser.add_argument("report_dir", type=str, help='path to the report directory')
    parser.add_argument("--ignore_dirs", type=str, help="paths to directories to be ignored", nargs="+")
    args = parser.parse_args()

    warnings = {}

    total_errors = 0

    substrings = []
    visited = []
    violations_dict = {}
    report_dir = os.path.abspath(args.report_dir.rstrip(os.sep))
    basedir = os.path.join(report_dir, "html_diffs")
    basedepth = len(basedir.split(os.sep))

    for path, dirs, files in os.walk(basedir):
        txt_files = filter(lambda file: file.endswith(".txt"), files)
        for file in txt_files:
            with open(os.path.join(path, file), "r") as fobj:
                checker_output = fobj.read()
            file_warnings = common.ParseCheckerOutput(checker_output)
            warnings.update(file_warnings)
            os.remove(os.path.join(path, file))

    for path, dirs, files in os.walk(basedir):
        rel_path = path.replace(basedir, "").strip(os.sep)
        rel_html_path = path.replace(report_dir, "")
        source_path = os.path.join(args.source_dir, rel_path)
        ignore = False
        if ".git" in path or ".svn" in path:
            ignore = True
        for directory in args.ignore_dirs:
            if source_path.startswith(directory):
                ignore = True
        if ignore:
            continue
        if path == basedir:
            visited.append(path)
            continue
        current_string = ""
        violations_dict[sanitize_path(source_path)] = 0

        # close the divs as needed
        prev_depth = len(visited[-1].split(os.sep))
        depth = len(path.split(os.sep))
        visited.append(path)
        if depth <= prev_depth:
            while depth <= prev_depth:
                substrings.append("</div>")
                prev_depth -= 1
        # create link + div for next sub-group
        current_string = "<a href='#{id}' class='list-group-item' data-toggle='collapse'><i class='glyphicon glyphicon-chevron-right'></i> {name} <span class='badge'>{source_path}</span></a>\n<div id='{id}' class='list-group collapse'>"
        current_string = current_string.format(id=sanitize_path(path), name=os.path.basename(path), source_path="{"+sanitize_path(source_path)+"}")
        substrings.append(current_string)
        if len(files) != 0:
            html_files = filter(lambda file: file.endswith(".html"), files)
            for file in html_files:
                html_file_path = os.path.join(rel_html_path, file).lstrip(os.sep)
                full_file_path = os.path.join(path, file)
                file_info = os.path.splitext(file)[0]
                filename, num_violations_str = os.path.splitext(file_info)
                num_violations = int(num_violations_str.strip("."))
                source_file = os.path.join(source_path, filename)
                if source_file in warnings:
                    for line in warnings[source_file]:
                        num_violations += len(warnings[source_file][line])
                    common.InsertHtmlLines(full_file_path, warnings[source_file])
                if num_violations == 0:
                    os.remove(full_file_path)
                    continue
                for key in violations_dict:
                    if key in sanitize_path(source_file):
                        violations_dict[key] += num_violations
                violations_dict[sanitize_path(source_file)] = num_violations
                total_errors += num_violations
                substrings.append("<a class='list-group-item file-item' data-url='./{html_file}'>{title}<span class='badge'>{source_file}</span></a>".format(html_file=html_file_path, title=filename, source_file="{"+sanitize_path(source_file)+"}"))

    while depth > basedepth:
        substrings.append("</div>")
        depth -= 1

    links = "\n".join(substrings)
    links = links.format(**violations_dict)

    # populate template from ./html/
    footer = ""
    with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), "../html/report_footer.html"), "r") as fobj:
        footer = fobj.read()
    with open(os.path.join(os.path.dirname(os.path.realpath(__file__)), "../html/report_index.html.in"), "r") as fobj:
        report_template = fobj.read()
    with open(os.path.join(args.report_dir, "index.html"), "w") as fobj:
        fobj.write(report_template.format(links=links, title=os.path.basename(args.source_dir), n=total_errors))
        fobj.write(footer)
    print("--------------------------------------------------------------------------------")
    print("Report index created at:\n{index_path}\nNumber of errors: {total_errors}".format(total_errors=total_errors, index_path=os.path.abspath(os.path.join(args.report_dir, "index.html"))))
    print("--------------------------------------------------------------------------------")
